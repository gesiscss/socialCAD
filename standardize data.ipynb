{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"../data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(filename, savename, id_alias, text_alias, construct_alias,\n",
    "                labels_alias, labels_mapping,\n",
    "                sep, construct = 'sentiment',\n",
    "                counterfactual_included = False, read_data = False, data = None):\n",
    "    \n",
    "    # read file and return pandas dataframe with only id, text and construct label (column names in lower case)\n",
    "    \n",
    "    if not counterfactual_included and not read_data:\n",
    "        data = pd.read_csv(filename, sep = sep)\n",
    "    else:\n",
    "        data = data\n",
    "        \n",
    "    data['text'] = data[text_alias]\n",
    "    data[construct] = data[construct_alias]\n",
    "    \n",
    "    if id_alias:\n",
    "        data['_id'] = data[id_alias]\n",
    "    else:\n",
    "        data['_id'] = range(len(data))\n",
    "        \n",
    "    if labels_mapping:\n",
    "        data[construct] = data[construct].map(labels_mapping)\n",
    "    \n",
    "    \n",
    "    data = data[['_id', 'text', construct]]\n",
    "    \n",
    "    print(data[construct].unique())\n",
    "    data.to_csv(savename, sep = \"\\t\", encoding = 'utf-8', index = False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for all Kaushik data\n",
    "train_type = ['train', 'test']\n",
    "data_type = {'orig' : 'original', 'new': 'counterfactual'}\n",
    "\n",
    "# for train in train_type:\n",
    "#     for data in data_type.keys():\n",
    "#         standardize(PATH+\"counterfactual_data/sentiment/%s/%s.tsv\" %(data, train),\n",
    "#                    savename = PATH+\"data/sentiment/%s/%s.csv\" %(train, data_type[data]),\n",
    "#                    id_alias = None,\n",
    "#                    text_alias = 'Text',\n",
    "#                    construct_alias = 'Sentiment',\n",
    "#                    labels_alias = ['Positive', 'Negative'],\n",
    "#                    labels_mapping = {'Positive' : 'positive', 'Negative': 'negative'},\n",
    "#                    sep = \"\\t\",\n",
    "#                    construct = 'sentiment')\n",
    "\n",
    "\n",
    "# standardize(PATH+\"tweet-sentiment-extraction/test.csv\",\n",
    "#                    savename = PATH+\"data/sentiment/test/kaggle.csv\",\n",
    "#                    id_alias = 'textID',\n",
    "#                    text_alias = 'text',\n",
    "#                    construct_alias = 'sentiment',\n",
    "#                    labels_alias = ['positive', 'negative', 'neutral'],\n",
    "#                    labels_mapping = None,\n",
    "#                    sep = \",\",\n",
    "#                    construct = 'sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for sexism data \n",
    "# out-domain, aka EXIST misogyny data\n",
    "\n",
    "data = pd.read_csv(PATH+\"data/sexism/EXIST2021_dataset/training/EXIST2021_training.tsv\", sep = \"\\t\")\n",
    "data = data[data['language'] == 'en']\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize(filename = PATH+\"data/sexism/EXIST2021_dataset/training/EXIST2021_training.tsv\",\n",
    "#                    savename = PATH+\"data/sexism/test/exist.csv\",\n",
    "#                    id_alias = 'id',\n",
    "#                    text_alias = 'text',\n",
    "#                    construct_alias = 'task1',\n",
    "#                    labels_alias = ['sexist', 'non-sexist'],\n",
    "#                    labels_mapping = None,\n",
    "#                    sep = \"\\t\",\n",
    "#                    construct = 'sexism',\n",
    "#                    read_data = True,\n",
    "#                    data = data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in-domain, aka the Samory data\n",
    "data = pd.read_csv(PATH+\"SAMORY_SEXIM.csv\", sep = \"\\t\")\n",
    "original = data[data['of_id'].isna()]\n",
    "counterfactual = data[~data['of_id'].isna()]\n",
    "\n",
    "# choose one counterfactual for each original sexist example\n",
    "counterfactual = counterfactual.groupby(\"of_id\").apply(lambda x:x.sample(n=1)).reset_index(0, drop=True)\n",
    "\n",
    "len(original), len(counterfactual), len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what about train-test split? Maybe 70-30 for now\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_original, test_original = train_test_split(original,\n",
    "                                                    stratify=original['sexist'], \n",
    "                                                    test_size=0.3)\n",
    "train_counterfactual, test_counterfactual = train_test_split(counterfactual,\n",
    "                                                    stratify=counterfactual['sexist'], \n",
    "                                                    test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_counterfactual), len(train_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_names = [\"train_original\", \"test_original\", \"train_counterfactual\", \"test_counterfactual\"]\n",
    "\n",
    "# for i, dataset in enumerate([train_original, test_original, train_counterfactual, test_counterfactual]):\n",
    "#     standardize(\"\",\n",
    "#                    savename = PATH+\"data/sexism/%s/%s.csv\" %(dataset_names[i].split(\"_\")[0],\n",
    "#                                                              dataset_names[i].split(\"_\")[1]),\n",
    "#                    id_alias = '_id',\n",
    "#                    text_alias = 'text',\n",
    "#                    construct_alias = 'sexist',\n",
    "#                    labels_alias = [True, False],\n",
    "#                    labels_mapping = {True: 'sexist', False : 'non-sexist'},\n",
    "#                    sep = \"\\t\",\n",
    "#                    construct = 'sexism',\n",
    "#                    counterfactual_included = True,\n",
    "#                    read_data = True,\n",
    "#                    data = dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### for hate speech data\n",
    "# standardize(filename, savename, id_alias, text_alias, construct_alias,\n",
    "#                 labels_alias, labels_mapping,\n",
    "#                 sep, construct = 'sentiment',\n",
    "#                 counterfactual_included = False, read_data = False, data = None):\n",
    "\n",
    "df = pd.read_csv(\"../data/data/hatespeech/VIDGEN_HATESPEECH.csv\")\n",
    "\n",
    "# refer to notebook 'explore data.ipynb' notebook in the DGHSD repo for details\n",
    "counterfactuals = df[df['id'].str.endswith('p')]\n",
    "\n",
    "# find their original counterpart\n",
    "counterfactual_ids = [i[:-1] for i in counterfactuals['id'].values]\n",
    "originals = df[df['id'].isin(counterfactual_ids)]\n",
    "\n",
    "# leave the dev set alone for now\n",
    "# for data in ['original_train', 'counterfactual_train', 'original_test', 'counterfactual_test']:\n",
    "#     data_type, split = data.split(\"_\")[0], data.split(\"_\")[1]\n",
    "    \n",
    "#     if data_type == 'counterfactual':\n",
    "#         data_slice = counterfactuals[counterfactuals['split'] == split]\n",
    "#     else:\n",
    "#         data_slice = originals[originals['split'] == split]\n",
    "        \n",
    "#     standardize(filename = None,\n",
    "#                 savename = PATH+\"data/hatespeech/%s/%s.csv\" %(split, data_type),\n",
    "#                 id_alias = 'id',\n",
    "#                 text_alias = 'text',\n",
    "#                 construct_alias = 'label',\n",
    "#                 labels_alias = ['hate', 'nothate'],\n",
    "#                 labels_mapping = {'hate': 'hate', 'nothate': 'not hate'},\n",
    "#                 sep = ',',\n",
    "#                 construct = 'hatespeech',\n",
    "#                 counterfactual_included = False,\n",
    "#                 read_data = True,\n",
    "#                 data = data_slice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out-of-domain data for hate speech: Hateval test set\n",
    "# standardize(filename = PATH+\"data/hatespeech/hateval2019/hateval2019_en_test.csv\",\n",
    "#                    savename = PATH+\"data/hatespeech/test/hateval.csv\",\n",
    "#                    id_alias = 'id',\n",
    "#                    text_alias = 'text',\n",
    "#                    construct_alias = 'HS',\n",
    "#                    labels_alias = [0, 1],\n",
    "#                    labels_mapping = {0 :'not hate', 1: 'hate'},\n",
    "#                    sep = \",\",\n",
    "#                    construct = 'hatespeech',\n",
    "#                    read_data = False,\n",
    "#                    data = data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_store_adversarial_data(original_data, construct = 'sentiment', attack = 'inv', sample_size = 100):\n",
    "    if attack == 'inv':\n",
    "        from textattack.augmentation import CheckListAugmenter\n",
    "        augmenter = CheckListAugmenter(pct_words_to_swap=0.2, transformations_per_example=1) #to-do: tweak params\n",
    "        \n",
    "        \n",
    "\n",
    "    elif attack == 'swap':\n",
    "        from textattack.augmentation import WordNetAugmenter\n",
    "        augmenter = WordNetAugmenter(pct_words_to_swap=0.2, transformations_per_example=1) #to-do: tweak params\n",
    "        \n",
    "    new_data = []\n",
    "    new_labels = []\n",
    "    old_sents = []\n",
    "        \n",
    "    original_data = original_data.sample(n = sample_size)\n",
    "    \n",
    "    docs = list(original_data['text'])\n",
    "    labels = list(original_data[construct])\n",
    "\n",
    "    # Augment\n",
    "    for n, doc in enumerate(docs):\n",
    "        if n % 10 == 0:\n",
    "            print(n, \" done.\")\n",
    "        # todo: split multisentences, seperately augment them and then collate them back together\n",
    "        from nltk.tokenize import sent_tokenize\n",
    "        sents = sent_tokenize(doc)\n",
    "        new_examples = []\n",
    "        \n",
    "        for sent in sents:\n",
    "            new_examples.append(augmenter.augment(sent)[0])\n",
    "        \n",
    "        #print(new_examples)\n",
    "        \n",
    "        adversarial_doc = ' '.join(new_examples)\n",
    "        new_data.append(adversarial_doc)\n",
    "        new_labels.append(labels[n])\n",
    "    \n",
    "    print(len(new_data))\n",
    "    print(len(docs))\n",
    "    \n",
    "    new_data = pd.DataFrame({\"text\": new_data, \"original\": docs, construct: new_labels})\n",
    "    new_data = new_data[new_data['original'] != new_data['text']]\n",
    "    new_data.to_csv(PATH+\"data/%s/test/adv_%s.csv\" %(construct, attack), sep = \"\\t\")\n",
    "    \n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### generate adversararial data and store\n",
    "\n",
    "attacks = [\n",
    "           'adv_inv',\n",
    "           'adv_swap']\n",
    "\n",
    "# for construct in ['sentiment']:\n",
    "#     for attack in attacks:\n",
    "#         base = pd.read_csv(PATH+\"data/%s/test/kaggle.csv\" %(construct), sep = '\\t')\n",
    "#         generate_and_store_adversarial_data(base, attack = attack[4:], sample_size = 500)\n",
    "        \n",
    "# for construct in ['hatespeech', 'sexism', 'sentiment']:\n",
    "#     for attack in attacks:\n",
    "#         base = pd.read_csv(PATH+\"data/%s/test/original.csv\" %(construct), sep = '\\t')\n",
    "#         generate_and_store_adversarial_data(base, construct, attack = attack[4:], sample_size = min(800, len(base)))        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = {'sentiment': {'original' : 'sentiment/train/original.csv',\\\n",
    "                               'counterfactual' : 'sentiment/train/counterfactual.csv'\n",
    "                              },\n",
    "            'sexism': {'original' : 'sexism/train/original.csv',\\\n",
    "                               'counterfactual' : 'sexism/train/counterfactual.csv'\n",
    "                              },\n",
    "            'hatespeech' : {'original' : 'hatespeech/train/original.csv',\\\n",
    "                               'counterfactual' : 'hatespeech/train/counterfactual.csv'\n",
    "                              },\n",
    "                }\n",
    "\n",
    "test_data = {'sentiment' : {'in-domain' : 'sentiment/test/original.csv',\n",
    "                            'out-domain' : 'sentiment/test/kaggle.csv',\n",
    "                            'adv_inv' : 'sentiment/test/adv_inv.csv',\n",
    "                            'adv_swap' : 'sentiment/test/adv_swap.csv',\n",
    "                            \n",
    "                           },\n",
    "             'sexism' : {'in-domain' : 'sexism/test/original.csv',\n",
    "                            'out-domain' : 'sexism/test/exist.csv',\n",
    "                            'adv_inv' : 'sexism/test/adv_inv.csv',\n",
    "                            'adv_swap' : 'sexism/test/adv_swap.csv',                            \n",
    "                           },\n",
    "             'hatespeech' : {'in-domain' : 'hatespeech/test/original.csv',\n",
    "                            'out-domain' : 'hatespeech/test/hateval.csv',\n",
    "                            'adv_inv' : 'hatespeech/test/adv_inv.csv',\n",
    "                            'adv_swap' : 'hatespeech/test/adv_swap.csv',                            \n",
    "                           },\n",
    "            }\n",
    "\n",
    "labels = {'sentiment' : {'positive': 1, 'negative' : 0},\n",
    "          'sexism' : {'sexist' : 1, 'non-sexist' : 0},\n",
    "          'hatespeech' : {'hate' : 1, 'not hate' : 0}\n",
    "                          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for construct in training_data.keys():\n",
    "    print(construct)\n",
    "    print()\n",
    "    for datatype in training_data[construct]:   \n",
    "        print('Training data')\n",
    "        print()\n",
    "        data = pd.read_csv(PATH+\"data/\" + training_data[construct][datatype], sep = \"\\t\")\n",
    "        data['%s_encoded' %construct] = data[construct].map( labels[construct])\n",
    "        print(datatype)\n",
    "        print()\n",
    "        print(data.groupby(\"%s_encoded\" %(construct)).size())\n",
    "        print()\n",
    "        print(data.groupby(\"%s\" %(construct)).size())\n",
    "        print()\n",
    "    \n",
    "    print(\"----------------------------------------------------------\")\n",
    "    print()\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for construct in training_data.keys():\n",
    "    print(construct)\n",
    "    print()\n",
    "\n",
    "    for datatype in test_data[construct]:\n",
    "        print('Test data')\n",
    "        print()\n",
    "        data = pd.read_csv(PATH+\"data/\" + test_data[construct][datatype], sep = \"\\t\")\n",
    "        print(datatype)\n",
    "        print()\n",
    "        print(data.groupby(construct).size())\n",
    "        print()\n",
    "    \n",
    "    print(\"----------------------------------------------------------\")\n",
    "    print()\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pair counterfactuals\n",
    "Pair the counterfactuals in training data with their original counterpart to find diffs. The format should be:\n",
    "original_id, original_text, original_label, counterfactual_text, counterfactual_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fix label mapping for sentiment and hatespeech [fixed 23.04]\n",
    "labels_mapping = {'hatespeech' : {'hate': 'hate', 'nothate': 'not hate'},\n",
    "                  'sentiment' : {'Positive' : 'positive', 'Negative': 'negative'}\n",
    "                 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paired_data = pd.DataFrame()\n",
    "## sentiment: use only the train data specified by Kaushik et al\n",
    "\n",
    "data = pd.read_csv(\"../data/counterfactual_data/sentiment/combined/paired/train_paired.tsv\", sep = \"\\t\")\n",
    "\n",
    "\n",
    "originals = []\n",
    "counterfactuals = []\n",
    "original_labels = []\n",
    "counterfactual_labels = []\n",
    "\n",
    "\n",
    "for n in range(0, len(data), 2):\n",
    "    originals.append(data['Text'].values[n])\n",
    "    original_labels.append(data['Sentiment'].values[n])\n",
    "    \n",
    "for n in range(1, len(data), 2):\n",
    "    counterfactuals.append(data['Text'].values[n])    \n",
    "    counterfactual_labels.append(data['Sentiment'].values[n])\n",
    "\n",
    "paired_data['original_text'] = originals\n",
    "paired_data['counterfactual_text'] = counterfactuals\n",
    "paired_data['original_label'] = original_labels\n",
    "paired_data['counterfactual_label'] = counterfactual_labels\n",
    "paired_data['original_id'] = [str(i) for i in range(0, len(paired_data))]\n",
    "paired_data['counterfactual_id'] = [i+'p' for i in paired_data['original_id']]\n",
    "\n",
    "\n",
    "paired_data['original_label'] = paired_data['original_label'].map(labels_mapping['sentiment'])\n",
    "paired_data['counterfactual_label'] = paired_data['counterfactual_label'].map(labels_mapping['sentiment'])\n",
    "\n",
    "paired_data.to_csv(\"../data/data/sentiment/train/paired.csv\", sep = \"\\t\", index = False)\n",
    "paired_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paired_data = pd.DataFrame()\n",
    "\n",
    "\n",
    "data = pd.read_csv(\"../data/data/sexism/SAMORY_SEXISM.csv\", sep = \"\\t\")\n",
    "cf_data = pd.read_csv(\"../data/data/sexism/train/counterfactual.csv\", sep = \"\\t\")\n",
    "original_data = pd.read_csv(\"../data/data/sexism/train/original.csv\", sep = \"\\t\")\n",
    "\n",
    "originals = []\n",
    "counterfactuals = []\n",
    "original_labels = []\n",
    "counterfactual_labels = []\n",
    "original_ids = []\n",
    "\n",
    "counterfactuals = cf_data['text']\n",
    "counterfactual_labels = cf_data['sexism']\n",
    "counterfactual_ids = cf_data['_id']\n",
    "\n",
    "for n, row in cf_data.iterrows():\n",
    "    cf_id = row['_id']\n",
    "    og_id = data[data['_id'] == cf_id]['of_id'].values[0]\n",
    "    og_tweet = data[data['_id'] == og_id]['text'].values[0]\n",
    "    og_tweet_label = data[data['_id'] == og_id]['sexist'].values[0]\n",
    "    \n",
    "    original_ids.append(og_id)\n",
    "    originals.append(og_tweet)\n",
    "    original_labels.append('sexist') # as we only have counterfactuals for sexist examples\n",
    "    \n",
    "    \n",
    "paired_data['original_id'] = original_ids\n",
    "paired_data['counterfactual_id'] = counterfactual_ids\n",
    "paired_data['original_text'] = originals\n",
    "paired_data['counterfactual_text'] = counterfactuals\n",
    "paired_data['original_label'] = original_labels\n",
    "paired_data['counterfactual_label'] = counterfactual_labels\n",
    "\n",
    "#paired_data.to_csv(\"../data/data/sexism/train/paired.csv\", sep = \"\\t\")\n",
    "paired_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paired_data = pd.DataFrame()\n",
    "## hate speech: use the training split specified by Vidgen et al\n",
    "\n",
    "data = pd.read_csv(\"../data/data/hatespeech/VIDGEN_HATESPEECH.csv\")\n",
    "\n",
    "counterfactual_df = data[data['id'].str.endswith('p')].reset_index()\n",
    "counterfactual_ids = [i[:-1] for i in counterfactual_df['id'].values]\n",
    "\n",
    "originals = []\n",
    "counterfactuals = []\n",
    "original_labels = []\n",
    "counterfactual_labels = []\n",
    "original_ids = []\n",
    "counterfactual_ids = []\n",
    "\n",
    "counterfactuals = list(counterfactual_df['text'].values)\n",
    "counterfactual_labels = list(counterfactual_df['label'].values)\n",
    "counterfactual_ids = list(counterfactual_df['id'].values)\n",
    "\n",
    "for n, row in counterfactual_df.iterrows():\n",
    "    cf_id = row['id'][:-1]\n",
    "    try:\n",
    "        og_id = data[data['id'] == cf_id]['id'].values[0]\n",
    "        og_tweet = data[data['id'] == og_id]['text'].values[0] \n",
    "        og_tweet_label = data[data['id'] == og_id]['label'].values[0]\n",
    "    \n",
    "        originals.append(og_tweet)\n",
    "        original_labels.append(og_tweet_label) \n",
    "        original_ids.append(og_id)\n",
    "    except: # apparently some counterfactuals do not have originals\n",
    "        print(cf_id)\n",
    "        \n",
    "        # drop those from the cf list        \n",
    "        \n",
    "        del counterfactuals[n]\n",
    "        del counterfactual_labels[n]\n",
    "        del counterfactual_ids[n]\n",
    "        \n",
    "        pass\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "paired_data['original_id'] = original_ids\n",
    "paired_data['counterfactual_id'] = counterfactual_ids\n",
    "paired_data['original_text'] = originals\n",
    "paired_data['counterfactual_text'] = counterfactuals\n",
    "paired_data['original_label'] = original_labels\n",
    "paired_data['counterfactual_label'] = counterfactual_labels\n",
    "\n",
    "paired_data['original_label'] = paired_data['original_label'].map(labels_mapping['hatespeech'])\n",
    "paired_data['counterfactual_label'] = paired_data['counterfactual_label'].map(labels_mapping['hatespeech'])\n",
    "\n",
    "#paired_data.to_csv(\"../data/data/hatespeech/train/paired.csv\", sep = \"\\t\")\n",
    "paired_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete data rows for EMNLP data submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   original_id counterfactual_id  negation_additions  negation_deletions  \\\n",
      "0            0                0p               False               False   \n",
      "1            1                1p               False               False   \n",
      "2            2                2p               False                True   \n",
      "3            3                3p               False                True   \n",
      "4            4                4p               False               False   \n",
      "\n",
      "   affect word_additions  affect word_deletions  gender word_additions  \\\n",
      "0                   True                   True                  False   \n",
      "1                   True                   True                  False   \n",
      "2                   True                   True                  False   \n",
      "3                   True                   True                  False   \n",
      "4                   True                   True                  False   \n",
      "\n",
      "   gender word_deletions  identity word_additions  identity word_deletions  \\\n",
      "0                  False                    False                    False   \n",
      "1                   True                    False                    False   \n",
      "2                  False                    False                    False   \n",
      "3                  False                    False                    False   \n",
      "4                  False                    False                    False   \n",
      "\n",
      "   hedges_additions  hedges_deletions  hate words_additions  \\\n",
      "0             False             False                 False   \n",
      "1             False             False                 False   \n",
      "2             False             False                 False   \n",
      "3             False              True                 False   \n",
      "4             False             False                 False   \n",
      "\n",
      "   hate words_deletions  \n",
      "0                 False  \n",
      "1                 False  \n",
      "2                 False  \n",
      "3                 False  \n",
      "4                 False  \n",
      "                original_id         counterfactual_id  negation_additions  \\\n",
      "0  5d65491ece2c6bd733478367  5d8cfe53e07686b7bfc2ce4c               False   \n",
      "1  5d654924ce2c6bd73347955a  5d8cfe53e07686b7bfc2ccf1               False   \n",
      "2  5d65491ece2c6bd733478397  5d8a6711e07686b7bfc2ca97               False   \n",
      "3  5d654904ce2c6bd733475d3e  5dc40160a72a9d5d0db94384               False   \n",
      "4  5d654922ce2c6bd733479036  5d8cfe53e07686b7bfc2cd8c               False   \n",
      "\n",
      "   negation_deletions  affect word_additions  affect word_deletions  \\\n",
      "0                True                   True                   True   \n",
      "1               False                  False                  False   \n",
      "2               False                  False                  False   \n",
      "3               False                  False                  False   \n",
      "4               False                   True                  False   \n",
      "\n",
      "   gender word_additions  gender word_deletions  identity word_additions  \\\n",
      "0                  False                   True                    False   \n",
      "1                  False                   True                    False   \n",
      "2                  False                  False                    False   \n",
      "3                  False                   True                    False   \n",
      "4                  False                   True                    False   \n",
      "\n",
      "   identity word_deletions  hedges_additions  hedges_deletions  \\\n",
      "0                    False             False             False   \n",
      "1                    False             False             False   \n",
      "2                    False             False             False   \n",
      "3                    False             False             False   \n",
      "4                    False             False             False   \n",
      "\n",
      "   hate words_additions  hate words_deletions  \n",
      "0                 False                 False  \n",
      "1                 False                 False  \n",
      "2                 False                 False  \n",
      "3                 False                 False  \n",
      "4                 False                 False  \n",
      "   original_id counterfactual_id  negation_additions  negation_deletions  \\\n",
      "0        19625            19625p               False               False   \n",
      "1        19637            19637p               False               False   \n",
      "2        19638            19638p               False               False   \n",
      "3        19640            19640p               False               False   \n",
      "4        19641            19641p               False               False   \n",
      "\n",
      "   affect word_additions  affect word_deletions  gender word_additions  \\\n",
      "0                  False                  False                  False   \n",
      "1                  False                  False                  False   \n",
      "2                  False                  False                  False   \n",
      "3                  False                  False                  False   \n",
      "4                  False                  False                  False   \n",
      "\n",
      "   gender word_deletions  identity word_additions  identity word_deletions  \\\n",
      "0                  False                    False                    False   \n",
      "1                  False                    False                    False   \n",
      "2                  False                    False                    False   \n",
      "3                  False                    False                    False   \n",
      "4                  False                    False                    False   \n",
      "\n",
      "   hedges_additions  hedges_deletions  hate words_additions  \\\n",
      "0             False             False                 False   \n",
      "1             False             False                 False   \n",
      "2             False             False                 False   \n",
      "3             False             False                 False   \n",
      "4             False             False                 False   \n",
      "\n",
      "   hate words_deletions  \n",
      "0                 False  \n",
      "1                 False  \n",
      "2                 False  \n",
      "3                 False  \n",
      "4                 False  \n"
     ]
    }
   ],
   "source": [
    "constructs = ['sentiment', 'sexism', 'hatespeech']\n",
    "for construct in constructs:\n",
    "    data = pd.read_csv(\"../data/data/%s/train/paired.csv\" %(construct), sep = \"\\t\")\n",
    "#     data = data[['original_id', 'counterfactual_id',\n",
    "#        'negation_additions', 'negation_deletions', 'affect word_additions',\n",
    "#        'affect word_deletions', 'gender word_additions',\n",
    "#        'gender word_deletions', 'identity word_additions',\n",
    "#        'identity word_deletions', 'hedges_additions', 'hedges_deletions',\n",
    "#        'hate words_additions', 'hate words_deletions']]\n",
    "#     data.to_csv(\"../data/data/%s/train/paired.csv\" %(construct), sep = \"\\t\", index = False)\n",
    "    print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36] *",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
